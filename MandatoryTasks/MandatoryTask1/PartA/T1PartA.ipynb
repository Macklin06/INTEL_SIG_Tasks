{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e546fdb6-ea84-46cd-868b-785e57e54c02",
   "metadata": {},
   "source": [
    "# Task A – Creating Word Embeddings\n",
    "\n",
    "In this task, I wanted to understand and experiment with how words can be represented as numbers.  \n",
    "Word embeddings basically capture the meaning of words in numerical form, so similar words are close to each other in vector space.\n",
    "\n",
    "I used the **NewsQA dataset** for this Part. \n",
    "I decided to create embeddings using two methods:\n",
    "- **Word2Vec (Skip-gram)** - a classical and common approach that learns based on context words.\n",
    "- **BERT** – a modern pretrained Transformer model that understands words in context.\n",
    "\n",
    "I will compare and save the embeddings for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6d1a02-7838-4a79-8f7c-4508c91b8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-ec54fbe500fc3b5c.parquet', 'validation': 'data/validation-00000-of-00001-3cf888b12fff1dd6.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/lucadiliello/newsqa/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff3b8dc-39e0-4b19-83b2-0c1b3799dbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>key</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>What was the amount of children murdered?</td>\n",
       "      <td>[19]</td>\n",
       "      <td>da0e6b66e04d439fa1ba23c32de07e50</td>\n",
       "      <td>[{'end': [295], 'start': [294]}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>When was Pandher sentenced to death?</td>\n",
       "      <td>[February.]</td>\n",
       "      <td>724f6eb9a2814e4fb2d7d8e4de846073</td>\n",
       "      <td>[{'end': [269], 'start': [261]}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>The court aquitted Moninder Singh Pandher of w...</td>\n",
       "      <td>[rape and murder]</td>\n",
       "      <td>d64cbb90e5134081acfa83d3e702408c</td>\n",
       "      <td>[{'end': [638], 'start': [624]}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>who was acquitted</td>\n",
       "      <td>[Moninder Singh Pandher]</td>\n",
       "      <td>fd7177ee6f1f4d62becd983a0305f503</td>\n",
       "      <td>[{'end': [216], 'start': [195]}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW DELHI, India (CNN) -- A high court in nort...</td>\n",
       "      <td>who was sentenced</td>\n",
       "      <td>[Moninder Singh Pandher]</td>\n",
       "      <td>cd25c69f631349748ccdeccaace66463</td>\n",
       "      <td>[{'end': [216], 'start': [195]}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  NEW DELHI, India (CNN) -- A high court in nort...   \n",
       "1  NEW DELHI, India (CNN) -- A high court in nort...   \n",
       "2  NEW DELHI, India (CNN) -- A high court in nort...   \n",
       "3  NEW DELHI, India (CNN) -- A high court in nort...   \n",
       "4  NEW DELHI, India (CNN) -- A high court in nort...   \n",
       "\n",
       "                                            question  \\\n",
       "0          What was the amount of children murdered?   \n",
       "1               When was Pandher sentenced to death?   \n",
       "2  The court aquitted Moninder Singh Pandher of w...   \n",
       "3                                  who was acquitted   \n",
       "4                                  who was sentenced   \n",
       "\n",
       "                    answers                               key  \\\n",
       "0                      [19]  da0e6b66e04d439fa1ba23c32de07e50   \n",
       "1               [February.]  724f6eb9a2814e4fb2d7d8e4de846073   \n",
       "2         [rape and murder]  d64cbb90e5134081acfa83d3e702408c   \n",
       "3  [Moninder Singh Pandher]  fd7177ee6f1f4d62becd983a0305f503   \n",
       "4  [Moninder Singh Pandher]  cd25c69f631349748ccdeccaace66463   \n",
       "\n",
       "                             labels  \n",
       "0  [{'end': [295], 'start': [294]}]  \n",
       "1  [{'end': [269], 'start': [261]}]  \n",
       "2  [{'end': [638], 'start': [624]}]  \n",
       "3  [{'end': [216], 'start': [195]}]  \n",
       "4  [{'end': [216], 'start': [195]}]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f995e-2a70-4ea3-a887-ca977598de6a",
   "metadata": {},
   "source": [
    "### 1. Understanding the Data\n",
    "\n",
    "The dataset has these columns:\n",
    "- `context` → paragraph of text from the article  \n",
    "- `question` → question asked from that paragraph  \n",
    "- `answers` → correct answer\n",
    "\n",
    "For word embeddings, I’ll combine the `context` and `question` only, because both are text that are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f55537e-1772-4cf6-b0d6-2ca9268da222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text entries: 74160\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['context'].astype(str) + \" \" + df['question'].astype(str) #combine columns context and question\n",
    "texts = df['text'].fillna(\"\").astype(str).tolist()\n",
    "print(\"Number of text entries:\", len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca50fd-10d0-4d73-bd29-ca3ec542d01c",
   "metadata": {},
   "source": [
    "### 2. Basic Text Preprocessing\n",
    "\n",
    "Before training, I cleaned the text to remove special characters, lowercase everything, and split into tokens (words).  \n",
    "I didn’t go too aggressive because the goal here is just to make it clean enough for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e269985-5fdf-4782-b48c-29ed9a0639d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/macklinchrissmiranda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'delhi', 'india', 'cnn', 'a', 'high', 'court', 'in', 'northern', 'india', 'on', 'friday', 'acquitted', 'a', 'wealthy', 'businessman', 'facing', 'the', 'death', 'sentence']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                   # lowercase all the characters\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # remove special characters\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "sentences = [clean_text(t) for t in texts]\n",
    "print(sentences[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdb448-6c1e-47b6-85ee-c8369a22b505",
   "metadata": {},
   "source": [
    "### 3. Word2Vec – Skip-gram Model\n",
    "\n",
    "I used **Word2Vec** from the Gensim library.  \n",
    "Skip-gram predicts surrounding words given a target word, which helps in understanding rare words better CBOW.  \n",
    "I used:\n",
    "- vector size = 100  \n",
    "- window = 8 (context size)\n",
    "- min_count = 3 (ignore rare words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cda50c-4315-4b86-9fe9-06ca070eb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 93390\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=100,\n",
    "    window=8,\n",
    "    min_count=3,\n",
    "    sg=1                   # 1 for skip-gram\n",
    ")\n",
    "\n",
    "print(\"Vocabulary size:\", len(w2v_model.wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d51a4-ee32-4383-a824-be5518c4bf6a",
   "metadata": {},
   "source": [
    "### 4. Saving Word2Vec Embeddings\n",
    "\n",
    "Now I saved all the word embeddings created by skip-gram as a CSV file in the format `(word, embedding)`.  \n",
    "Each word will have a 100-dimensional vector as the vector_size given above was 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7127bb-c722-4ba7-8058-487a1ea8df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec embeddings saved!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"word2vec_embeddings.csv\", \"w\", newline=\"\") as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow([\"word\", \"embedding\"])\n",
    "    for word in w2v_model.wv.index_to_key:\n",
    "        write.writerow([word, w2v_model.wv[word].tolist()])\n",
    "\n",
    "print(\"Word2Vec embeddings saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23439f0a-d7cf-4730-8098-cfd9866dd460",
   "metadata": {},
   "source": [
    "### 5. Checking Similar Words\n",
    "\n",
    "I tested some example words to see if the model learned meaningful relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0a73a7-e27c-4ba6-be29-70047df17c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('indias', 0.7427746057510376), ('delhi', 0.7172093391418457), ('indian', 0.6961739659309387), ('mumbai', 0.6740450263023376), ('pallavakam', 0.646253228187561)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar('india', topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31028286-ada4-4947-9d16-bc789610a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('judge', 0.8309882879257202), ('supreme', 0.8072786927223206), ('kirkwood', 0.7761055827140808), ('appeals', 0.7570107579231262), ('nowjustice', 0.7543099522590637)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar('court', topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246612c1-33b2-4b65-b0d0-06e7a4919378",
   "metadata": {},
   "source": [
    "# Use of Pretrained Models\n",
    "I also wanted use BERT Model as it is good for contextual embedding for rare words and also for words with different uses based on the context, but since I will be using those in later Parts of this Task, i skipped it for Part A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198314f-74ab-4218-95ab-00ff7c233fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (T1venv)",
   "language": "python",
   "name": "t1venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
